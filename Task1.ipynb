{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBKXI07IGRLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9liwp7rH7tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Metrics\n",
        "def mean_square_error(y, y_pred):\n",
        "    return np.mean(np.square(y - y_pred))\n",
        "\n",
        "def root_mean_square_error(y, y_pred):\n",
        "    return mean_square_error(y, y_pred)**0.5\n",
        "  \n",
        "def r2_score(y, y_pred):\n",
        "    y_avg = y.mean()\n",
        "    ss_total = np.sum(np.square(y - y_avg))\n",
        "    ss_err = np.sum(np.square(y - y_pred))\n",
        "    return 1 - ss_err/ss_total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlriatCAITNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Utils\n",
        "def add_biases(X):\n",
        "    return np.hstack((X, np.ones((X.shape[0],1))))\n",
        "  \n",
        "def linear(X, w):\n",
        "    return np.matmul(w, X.T)\n",
        "  \n",
        "def preprocess(X_train, X_test):\n",
        "    #Standardize\n",
        "    X_mean, X_std = X_train.mean(axis=0), X_train.std(axis=0)\n",
        "    X_train = (X_train - X_mean)/X_std\n",
        "    X_test = (X_test - X_mean)/X_std\n",
        "    \n",
        "    #Remove NaN in 37 column\n",
        "    np.nan_to_num(X_train, copy=False)\n",
        "    np.nan_to_num(X_test, copy=False)\n",
        "    \n",
        "    #Biases\n",
        "    X_train = add_biases(X_train)\n",
        "    X_test = add_biases(X_test)\n",
        "    \n",
        "    return X_train, X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qddcwTa4GKSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SGD  \n",
        "def compute_gradient_on_batch(X, y, w):\n",
        "  \n",
        "    batch_size, feature_count = X.shape\n",
        "    grad = np.zeros((batch_size, feature_count))\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "        grad[i, :] = X[i, :]*(w @ X[i] - y[i])\n",
        "    \n",
        "    return grad\n",
        "\n",
        "def stochastic_gradient_descent(X, y, lr=1e-2, max_epoch=10, \n",
        "                                batch_size=1):\n",
        "    weight_dist = np.inf\n",
        "    w = np.random.randn(X.shape[1])    #init w\n",
        "    errors = []\n",
        "    \n",
        "    iters = X.shape[0] // batch_size\n",
        "    if (X.shape[0] % batch_size > 0):\n",
        "        iters += 1\n",
        "    \n",
        "    for epoch in range(max_epoch):\n",
        "        for i in range(iters):\n",
        "            \n",
        "            X_batch = X[i*batch_size:(i+1)*batch_size]\n",
        "            y_batch = y[i*batch_size:(i+1)*batch_size]\n",
        "\n",
        "            grad = compute_gradient_on_batch(X_batch, y_batch, w)\n",
        "            w = w - lr * np.mean(grad, axis=0)\n",
        "            \n",
        "        errors.append(mean_square_error(y, linear(X, w)))\n",
        "    \n",
        "    return w, errors\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbuktrM5IZ_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Folds\n",
        "class KFolds:\n",
        "    def __init__(self, X, y, k=5):\n",
        "      \n",
        "        self.k = k\n",
        "        \n",
        "        fold_size = X.shape[0]//k\n",
        "        if X.shape[0] % k > 0:\n",
        "            fold_size += 1\n",
        "            \n",
        "        self.X_folds = [X[i*fold_size:(i+1)*fold_size] for i in range(k)]\n",
        "        self.y_folds = [y[i*fold_size:(i+1)*fold_size] for i in range(k)]\n",
        "        \n",
        "    def get_fold(self, fold_i):\n",
        "        \n",
        "        X_cv = self.X_folds[fold_i]\n",
        "        y_cv = self.y_folds[fold_i]\n",
        "        \n",
        "        X_train = np.concatenate([self.X_folds[i] for i in range(self.k) if i != fold_i])\n",
        "        y_train = np.concatenate([self.y_folds[i] for i in range(self.k) if i != fold_i])\n",
        "        \n",
        "        return X_train, y_train, X_cv, y_cv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir879LnbGzQr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "21d56f2a-b025-4d71-a585-f239d454f06e"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00363/Dataset.zip\n",
        "!unzip -q Dataset.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-11 11:52:41--  https://archive.ics.uci.edu/ml/machine-learning-databases/00363/Dataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19055526 (18M) [application/x-httpd-php]\n",
            "Saving to: ‘Dataset.zip’\n",
            "\n",
            "Dataset.zip         100%[===================>]  18.17M  22.5MB/s    in 0.8s    \n",
            "\n",
            "2019-09-11 11:52:47 (22.5 MB/s) - ‘Dataset.zip’ saved [19055526/19055526]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9yG5P9WIiPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('Dataset/Training/Features_Variant_1.csv',header=None)\n",
        "\n",
        "y = train_df[53].values\n",
        "X = train_df.drop(columns=[53]).values\n",
        "\n",
        "#Shuffle\n",
        "p = np.random.permutation(X.shape[0])\n",
        "X, y = X[p], y[p]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okgnz9vgIpu7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "452dab1b-4da8-4325-c01a-cb1a9d3c5997"
      },
      "source": [
        "kfold = KFolds(X,y,k=5)\n",
        "rmse_list = []\n",
        "r2_list = []\n",
        "weights_list = []\n",
        "\n",
        "for i in range(kfold.k):\n",
        "    X_train, y_train, X_cv, y_cv = kfold.get_fold(i)\n",
        "    X_train, X_cv = preprocess(X_train, X_cv)\n",
        "    \n",
        "    w, errors = stochastic_gradient_descent(X_train, y_train, lr=1e-2, max_epoch=20, batch_size=1000)\n",
        "    y_pred = linear(X_cv, w)\n",
        "    \n",
        "    rmse_list.append(root_mean_square_error(y_cv, y_pred))\n",
        "    r2_list.append(r2_score(y_cv, y_pred))\n",
        "    weights_list.append(w)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMko3AqjKY2X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "da2cd638-4ed8-41e6-fd2f-ad201eaf472c"
      },
      "source": [
        "print(\"Folds\\t│{}\\t{}\\t{}\\t{}\\t{}\\t│mean\\tstd\".format(*range(kfold.k)))\n",
        "print(\"────────┼───────────────────────────────────────┼─────────────\")\n",
        "print(\"RMSE\\t│{:.1f}\\t{:.1f}\\t{:.1f}\\t{:.1f}\\t{:.1f}\\t│{:.2f}\\t{:.2f}\".format(*rmse_list, np.array(rmse_list).mean(), np.array(rmse_list).std()))\n",
        "print(\"R2\\t│{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t│{:.3f}\\t{:.3f}\".format(*r2_list, np.array(r2_list).mean(), np.array(r2_list).std()))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Folds\t│0\t1\t2\t3\t4\t│mean\tstd\n",
            "────────┼───────────────────────────────────────┼─────────────\n",
            "RMSE\t│28.0\t26.2\t32.3\t33.6\t28.2\t│29.66\t2.80\n",
            "R2\t│0.333\t0.324\t0.207\t0.264\t0.367\t│0.299\t0.057\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}