{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andre6o6/mlcourse-2019/blob/master/Task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY6GA3gnG9mi",
        "colab_type": "code",
        "outputId": "3ae0b9c3-aae3-49d6-dc8b-d808fb034ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "!wget https://archive.org/download/nf_prize_dataset.tar/nf_prize_dataset.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-22 11:23:00--  https://archive.org/download/nf_prize_dataset.tar/nf_prize_dataset.tar.gz\n",
            "Resolving archive.org (archive.org)... 207.241.224.2\n",
            "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ia800205.us.archive.org/7/items/nf_prize_dataset.tar/nf_prize_dataset.tar.gz [following]\n",
            "--2019-10-22 11:23:01--  https://ia800205.us.archive.org/7/items/nf_prize_dataset.tar/nf_prize_dataset.tar.gz\n",
            "Resolving ia800205.us.archive.org (ia800205.us.archive.org)... 207.241.230.25\n",
            "Connecting to ia800205.us.archive.org (ia800205.us.archive.org)|207.241.230.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 697552028 (665M) [application/octet-stream]\n",
            "Saving to: ‘nf_prize_dataset.tar.gz’\n",
            "\n",
            "nf_prize_dataset.ta 100%[===================>] 665.24M  2.06MB/s    in 11m 8s  \n",
            "\n",
            "2019-10-22 11:34:10 (1019 KB/s) - ‘nf_prize_dataset.tar.gz’ saved [697552028/697552028]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBTHWLCHOXdT",
        "colab_type": "code",
        "outputId": "affdd084-70d2-4e63-cc72-b0734befe0e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7rxCmzyQKL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!cp nf_prize_dataset.tar.gz '/gdrive/My Drive/data/'\n",
        "!cp '/gdrive/My Drive/data/nf_prize_dataset.tar.gz' ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VITLCngHQku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xzf nf_prize_dataset.tar.gz\n",
        "!tar -xf download/training_set.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqo7uucdIisG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooKVQF4VmnqB",
        "colab_type": "text"
      },
      "source": [
        "Factorization machine from this paper: \n",
        "https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3r9U2FPZbQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FactorizationMachine:\n",
        "    def __init__(self, n, k):\n",
        "        self.w0 = 0\n",
        "        self.w = np.zeros(n)\n",
        "        self.v = np.zeros((n,k))\n",
        "\n",
        "        self.lr = 1e-2\n",
        "\n",
        "        self.x_batch = None\n",
        "\n",
        "    def step_lr(self, alpha=0.1):\n",
        "        self.lr = self.lr * alpha\n",
        "    \n",
        "    def forward(self, x):\n",
        "        #Cache\n",
        "        self.x_batch = x\n",
        "        \n",
        "        # Linear\n",
        "        first = x @ self.w\n",
        "        # Pairwise interactions\n",
        "        second = 0.5 * np.sum(np.square(x @ self.v) - x.power(2) @ np.square(self.v), axis=-1)\n",
        "\n",
        "        y = self.w0 + first + second\n",
        "        return y\n",
        "\n",
        "    def backward(self, dLdy):\n",
        "        if self.x_batch is None:\n",
        "            assert 0, 'Call forward first'\n",
        "\n",
        "        # Bias grad, dy/dw0 = 1\n",
        "        dLdw0 = np.mean(dLdy)\n",
        "        \n",
        "        # Np mean of sparse matrix gives matrix, so we cast to np array\n",
        "        # and take 0'th element for correct shapes - (n,)\n",
        "        dLdw = np.array(np.mean(self.x_batch.multiply(dLdy.reshape(-1,1)), axis=0))[0]\n",
        "\n",
        "        \n",
        "        # Could precompute this in forward pass\n",
        "        v_dot_x = scipy.sparse.csr_matrix(self.x_batch @ self.v)\n",
        "        \n",
        "        # For every batch sample, calculate dL/dv = dL/dy * dy/dw \n",
        "        dLdv = [(x.reshape(-1,1).multiply(v_dot_x.getrow(i)) -    \\\n",
        "                 x.power(2).reshape(-1,1).multiply(self.v)) * dLdy[i] \n",
        "                for i,x in enumerate(self.x_batch)]\n",
        "        \n",
        "        # Mean gradients over all batch samples\n",
        "        batch_size = self.x_batch.shape[0]\n",
        "        dLdv = scipy.sum(dLdv, axis=0).toarray() / batch_size\n",
        "\n",
        "        # Update weights\n",
        "        self.w0 -= self.lr * dLdw0\n",
        "        self.w -= self.lr * dLdw\n",
        "        self.v -= self.lr * dLdv\n",
        "        \n",
        "        #Clear cache\n",
        "        self.x_batch = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNfsvmL5S0Ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MSE:\n",
        "    def __init__(self):\n",
        "        self.err = None\n",
        "    def forward(self, y_true, y_pred):\n",
        "        self.err = y_true - y_pred\n",
        "        return np.mean(np.square(self.err))\n",
        "    def backward(self):\n",
        "        if self.err is None:\n",
        "            assert 0, 'Call forward first'\n",
        "        return -2 * self.err"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1FAJnsajTHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAwOKrV4Iiwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "#print(len(os.listdir('training_set/')))\n",
        "\n",
        "#with open('training_set/mv_0010218.txt') as f:\n",
        "#  print(f.readlines())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEbtoaYBUkM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transactions = np.zeros((100480507, 3), dtype=int)\n",
        "i = 0\n",
        "\n",
        "root = 'training_set/'\n",
        "for filename in os.listdir(root):\n",
        "    file = root + filename\n",
        "    with open(file) as f:\n",
        "        lines = f.readlines()\n",
        "        movie_idx = int(lines[0].split(':')[0])\n",
        "        for line in lines[1:]:\n",
        "            user_idx, score, _ = line.split(',')\n",
        "            user_idx, score = int(user_idx), int(score)\n",
        "            transactions[i] = movie_idx, user_idx, score\n",
        "            i+=1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RJCAH2S0AYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.shuffle(transactions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV-AZimeREyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('transactions.npy', transactions)\n",
        "#!cp transactions.npy '/gdrive/My Drive/data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfeH2wNoQRAD",
        "colab_type": "code",
        "outputId": "e4ef7731-48e8-4d21-c087-1d4244f0cdbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3UvZIwYFQaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transactions = np.load('transactions.npy')\n",
        "transactions = transactions.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4VZ4kl6uNp1",
        "colab_type": "code",
        "outputId": "64e143e0-1259-4626-bf28-8c5e76d3191c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "transactions.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100480507, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf7QPfatyCkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_movies = 17770    #1..17770\n",
        "\n",
        "n_users = 480189\n",
        "user_idxs = {x:i for i,x in enumerate(set(transactions[:, 1]))}\n",
        "\n",
        "#scores = {1, 2, 3, 4, 5}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTOXvKu2I6a-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transactions = transactions[:1000000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOR7uhUB0Qbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "from scipy.sparse import csc_matrix\n",
        "\n",
        "def onehot(X):\n",
        "    dtype = np.uint8\n",
        "    rows = np.arange(X.size)\n",
        "    cols = X\n",
        "    data = np.ones(X.size, dtype=dtype)\n",
        "    return csc_matrix((data, (rows,cols)))  #coo?\n",
        "\n",
        "#Subtract 1 so that indexes are from 0 to 17770\n",
        "oh_movies = onehot(transactions[:, 0] - 1)\n",
        "#Map users to 0..480189 using user_idxs dict\n",
        "oh_users = onehot(np.vectorize(user_idxs.get)(transactions[:, 1]))\n",
        "\n",
        "y = transactions[:, 2]\n",
        "X = scipy.sparse.hstack((oh_movies, oh_users)).tocsr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_y0kJfe7tvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = X.shape[1]\n",
        "k = 10\n",
        "model = FactorizationMachine(n,k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYYsr4VmDvVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = MSE()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4VoYbXd-C1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_ratio = 0.05\n",
        "test_split = int(X.shape[0] * test_ratio)\n",
        "X_train, X_test, y_train, y_test = X[test_split:], X[:test_split], y[test_split:], y[:test_split]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfW3noFi-9Lr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1000\n",
        "\n",
        "iters = X_train.shape[0] // batch_size\n",
        "if (X_train.shape[0] % batch_size > 0):\n",
        "    iters += 1\n",
        "\n",
        "def get_batch_numpy(i):\n",
        "    return X_train[i*batch_size:(i+1)*batch_size], \\\n",
        "           y_train[i*batch_size:(i+1)*batch_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMAQCU4fGPtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def r2_score(y, y_pred):\n",
        "    y_avg = y.mean()\n",
        "    ss_total = np.sum(np.square(y - y_avg))\n",
        "    ss_err = np.sum(np.square(y - y_pred))\n",
        "    return 1 - ss_err/ss_total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-cvgqtZ8XLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1\n",
        "for epoch in range(epochs):\n",
        "    for i in range(iters):\n",
        "        X_batch, y_batch = get_batch_numpy(i)\n",
        "\n",
        "        y_pred = model.forward(X_batch)\n",
        "        loss = criterion.forward(y_batch, y_pred)\n",
        "\n",
        "        dLdy = criterion.backward()\n",
        "        model.backward(dLdy)\n",
        "\n",
        "        print(\"[{}]({}) l = {}\".format(epoch, i, loss))\n",
        "        print(\"\\t r2 = {}\".format(r2_score(y_batch, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IW2O9HjUq-O",
        "colab_type": "code",
        "outputId": "a2b98cc1-f102-420a-d44d-1371a4a51bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "y_pred = model.forward(X_test)\n",
        "mse = criterion.forward(y_test, y_pred)\n",
        "print(\"RMSE =\", mse**0.5)\n",
        "print(\"R2 =\", r2_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE = 1.133851551679614\n",
            "R2 = 0.05384853860236494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie93olA6_NvI",
        "colab_type": "code",
        "outputId": "5ad09a3a-4d88-4c22-ac55-b834d4c10486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3340234605620474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRw2bDFK5IzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdfweGyqUyyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FactorizationMachineDense:\n",
        "    def __init__(self, n, k):\n",
        "        self.w0 = 0\n",
        "        self.w = np.zeros(n)\n",
        "        self.v = np.zeros((n,k))\n",
        "\n",
        "        self.lr = 0.001\n",
        "\n",
        "        #cache\n",
        "        self.x_batch = None\n",
        "        self.v_dot_x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        #Cache\n",
        "        self.x_batch = x\n",
        "        self.v_dot_x = x @ self.v\n",
        "        \n",
        "        first = x @ self.w\n",
        "        second = 0.5 * np.sum(np.square(v_dot_x) - np.square(x) @ np.square(self.v), axis=-1)\n",
        "        y = self.w0 + first + second\n",
        "        return y\n",
        "\n",
        "    def backward(self, dLdy):\n",
        "        if self.x_batch is None:\n",
        "            assert 0, 'Call forward first'\n",
        "\n",
        "        dLdw0 = np.mean(dLdy)\n",
        "        dLdw = np.mean(self.x_batch * dLdy, axis=0)\n",
        "\n",
        "        b = self.x_batch.shape[0]\n",
        "        n, k = self.v.shape\n",
        "        dLdv = np.zeros((b,n,k))\n",
        "        for i,x in enumerate(self.x_batch):\n",
        "            dLdv[i] = (x[:, None] * (self.v_dot_x[i]) - self.v * np.square(x)[:, None]) * dLdy[i]\n",
        "        dLdv = np.mean(dLdv, axis=0)\n",
        "\n",
        "\n",
        "        self.w0 -= self.lr * dLdw0\n",
        "        self.w -= self.lr * dLdw\n",
        "        self.v -= self.lr * dLdv\n",
        "        \n",
        "        #Clear cache\n",
        "        self.x_batch = None\n",
        "        self.v_dot_x = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7acdPuwZjWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class FactorizationMachineTorch:\n",
        "    def __init__(self, n, k):\n",
        "        self.w0 = torch.tensor(0.1)\n",
        "        self.w = 0.01*torch.randn(n)\n",
        "        self.v = 0.01*torch.randn(n,k)\n",
        "\n",
        "        self.lr = 0.01\n",
        "        # Adam hypers\n",
        "        self.beta1 = 0.9\n",
        "        self.beta2 = 0.999\n",
        "        # Adam moments\n",
        "        self.v_dw0 = torch.zeros_like(self.w0.data)\n",
        "        self.s_dw0 = torch.zeros_like(self.w0.data)\n",
        "        self.v_dw = torch.zeros_like(self.w.data)\n",
        "        self.s_dw = torch.zeros_like(self.w.data)\n",
        "        self.v_dv = torch.zeros_like(self.v.data)\n",
        "        self.s_dv = torch.zeros_like(self.v.data)\n",
        "        # \n",
        "        self.t = 0\n",
        "        self.eps = 1e-8\n",
        "\n",
        "        #cache\n",
        "        self.x_batch = None\n",
        "        self.v_dot_x = None\n",
        "\n",
        "    def to(self, device):\n",
        "        self.w0 = self.w0.to(device)\n",
        "        self.w = self.w.to(device)\n",
        "        self.v = self.v.to(device)\n",
        "\n",
        "        self.v_dw0 = self.v_dw0.to(device)\n",
        "        self.s_dw0 = self.s_dw0.to(device)\n",
        "        self.v_dw = self.v_dw.to(device)\n",
        "        self.s_dw = self.s_dw.to(device)\n",
        "        self.v_dv = self.v_dv.to(device)\n",
        "        self.s_dv = self.s_dv.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #Cache\n",
        "        self.x_batch = x\n",
        "        self.v_dot_x = torch.mm(x, self.v)\n",
        "        \n",
        "        return self.w0   \\\n",
        "               + torch.matmul(x, self.w)   \\\n",
        "               + 0.5 * torch.sum(self.v_dot_x.pow(2) - torch.mm(x.pow(2), self.v.pow(2)), dim=-1)\n",
        "         \n",
        "    def backward(self, dLdy):\n",
        "        if self.x_batch is None:\n",
        "            assert 0, 'Call forward first'\n",
        "\n",
        "        dLdw0 = torch.mean(dLdy)\n",
        "        dLdw = torch.mean(self.x_batch * dLdy.view(-1,1), dim=0)\n",
        "\n",
        "        b = self.x_batch.shape[0]\n",
        "        n, k = self.v.shape\n",
        "        #dLdv = torch.zeros(n,k, device=device)\n",
        "        #for xi, v_dot_xi, dLdyi in zip(self.x_batch, self.v_dot_x, dLdy):\n",
        "        #    dLdv.add_(dLdyi, xi.view(-1,1) * v_dot_xi - self.v * xi.pow(2).view(-1,1))\n",
        "        #dLdv.div_(b)\n",
        "        dLdv = torch.einsum('bn, bk -> bnk', (self.x_batch, self.v_dot_x))\n",
        "        dLdv.sub_(torch.einsum('bn, nk -> bnk', (self.x_batch.pow(2), self.v)))\n",
        "        dLdv.mul_(dLdy.view(-1,1,1))\n",
        "        dLdv = dLdv.mean(dim=0)\n",
        "        \n",
        "\n",
        "        #ADAM: estimate moments\n",
        "        self.v_dw0.mul_(self.beta1).add_(1 - self.beta1, dLdw0)\n",
        "        self.s_dw0.mul_(self.beta2).addcmul_(1 - self.beta2, dLdw0, dLdw0)\n",
        "        self.v_dw.mul_(self.beta1).add_(1 - self.beta1, dLdw)\n",
        "        self.s_dw.mul_(self.beta2).addcmul_(1 - self.beta2, dLdw, dLdw)\n",
        "        self.v_dv.mul_(self.beta1).add_(1 - self.beta1, dLdv)\n",
        "        self.s_dv.mul_(self.beta2).addcmul_(1 - self.beta2, dLdv, dLdv)\n",
        "        #ADAM: correct moments\n",
        "        self.t+=1\n",
        "        bias_correction1 = 1 - self.beta1**self.t\n",
        "        bias_correction2 = 1 - self.beta2**self.t\n",
        "\n",
        "        denom_w0 = (self.s_dw0.sqrt() / math.sqrt(bias_correction2)).add_(self.eps)        \n",
        "        denom_w = (self.s_dw.sqrt() / math.sqrt(bias_correction2)).add_(self.eps)      \n",
        "        denom_v = (self.s_dv.sqrt() / math.sqrt(bias_correction2)).add_(self.eps) \n",
        "\n",
        "        #ADAM: Update weights\n",
        "        step_size = self.lr / bias_correction1\n",
        "        self.w0.data.addcdiv_(-step_size, self.v_dw0, denom_w0)\n",
        "        self.w.data.addcdiv_(-step_size, self.v_dw, denom_w)\n",
        "        self.v.data.addcdiv_(-step_size, self.v_dv, denom_v)\n",
        "        \n",
        "        #Clear cache\n",
        "        self.x_batch = None\n",
        "        self.v_dot_x = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPsQC62641f0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MSE_torch:\n",
        "    def __init__(self):\n",
        "        self.err = None\n",
        "    def forward(self, y_true, y_pred):\n",
        "        self.err = y_true - y_pred\n",
        "        return torch.mean((self.err).pow(2))\n",
        "    def backward(self):\n",
        "        if self.err is None:\n",
        "            assert 0, 'Call forward first'\n",
        "        return -2 * self.err"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHLAPqbS5z4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def r2_score(y, y_pred):\n",
        "    y_avg = y.mean()\n",
        "    ss_total = np.sum(np.square(y - y_avg))\n",
        "    ss_err = np.sum(np.square(y - y_pred))\n",
        "    return 1 - ss_err/ss_total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhdIlvqW5r8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = X.shape[1]\n",
        "k = 10\n",
        "model = FactorizationMachineTorch(n,k)\n",
        "model.to(device)\n",
        "\n",
        "criterion = MSE_torch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiIHt9j8dRbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "\n",
        "iters = X_train.shape[0] // batch_size\n",
        "if (X_train.shape[0] % batch_size > 0):\n",
        "    iters += 1\n",
        "\n",
        "def get_batch_torch(i):\n",
        "    return torch.tensor(X_train[i*batch_size:(i+1)*batch_size].toarray(), dtype=torch.float32), \\\n",
        "           torch.tensor(y_train[i*batch_size:(i+1)*batch_size], dtype=torch.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI3ri2Ec5r5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "history = []\n",
        "history_r2 = []\n",
        "epochs = 1\n",
        "for epoch in range(epochs):\n",
        "    for i in range(iters):\n",
        "        X_batch, y_batch = get_batch_torch(i)\n",
        "\n",
        "        y_pred = model.forward(X_batch.to(device))\n",
        "        loss = criterion.forward(y_batch.to(device), y_pred)\n",
        "\n",
        "        dLdy = criterion.backward()\n",
        "        model.backward(dLdy)\n",
        "\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print(\"[{}]({}) l = {}\".format(epoch, i, loss))\n",
        "            r2 = r2_score(y_batch.cpu().numpy(), y_pred.cpu().numpy())\n",
        "            history_r2.append(loss)\n",
        "            print(\"\\t r2 = {}\".format(r2))\n",
        "\n",
        "        history.append(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X7nhCenphsp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "1322ab41-0f6f-484c-9a20-44ba471e3aff"
      },
      "source": [
        "%pylab inline\n",
        "plt.plot(history)\n",
        "plt.ylabel(\"MSE\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'MSE')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlmizxgdBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpoTOC3gXApD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "202c7cb5-9f6b-4066-a09a-2fd716a50d08"
      },
      "source": [
        "import tqdm\n",
        "\n",
        "batch_size = 1000\n",
        "iters = X_test.shape[0] // batch_size\n",
        "if (X_test.shape[0] % batch_size > 0):\n",
        "    iters += 1\n",
        "\n",
        "def get_test(i):\n",
        "    return torch.tensor(X_test[i*batch_size:(i+1)*batch_size].toarray(), dtype=torch.float32)\n",
        "\n",
        "y_pred = np.zeros(y_test.shape)\n",
        "\n",
        "for i in tqdm.tqdm(range(iters)):\n",
        "    X_batch = get_test(i)\n",
        "    y_pred[i*batch_size:(i+1)*batch_size] = model.forward(X_batch.to(device)).cpu().numpy()\n",
        "\n",
        "print()\n",
        "print(\"RMSE =\", MSE().forward(y_test, y_pred))\n",
        "print(\"R2 =\", r2_score(y_test, y_pred))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [01:04<00:00,  1.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RMSE = 0.39525254984356556\n",
            "R2 = 0.6567962289234461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}