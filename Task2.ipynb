{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andre6o6/mlcourse-2019/blob/master/Task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooKVQF4VmnqB",
        "colab_type": "text"
      },
      "source": [
        "Factorization machine from this paper: \n",
        "https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY6GA3gnG9mi",
        "colab_type": "code",
        "outputId": "3ae0b9c3-aae3-49d6-dc8b-d808fb034ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "!wget https://archive.org/download/nf_prize_dataset.tar/nf_prize_dataset.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-22 11:23:00--  https://archive.org/download/nf_prize_dataset.tar/nf_prize_dataset.tar.gz\n",
            "Resolving archive.org (archive.org)... 207.241.224.2\n",
            "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ia800205.us.archive.org/7/items/nf_prize_dataset.tar/nf_prize_dataset.tar.gz [following]\n",
            "--2019-10-22 11:23:01--  https://ia800205.us.archive.org/7/items/nf_prize_dataset.tar/nf_prize_dataset.tar.gz\n",
            "Resolving ia800205.us.archive.org (ia800205.us.archive.org)... 207.241.230.25\n",
            "Connecting to ia800205.us.archive.org (ia800205.us.archive.org)|207.241.230.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 697552028 (665M) [application/octet-stream]\n",
            "Saving to: ‘nf_prize_dataset.tar.gz’\n",
            "\n",
            "nf_prize_dataset.ta 100%[===================>] 665.24M  2.06MB/s    in 11m 8s  \n",
            "\n",
            "2019-10-22 11:34:10 (1019 KB/s) - ‘nf_prize_dataset.tar.gz’ saved [697552028/697552028]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEbtoaYBUkM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "#Load data\n",
        "transactions = np.zeros((100480507, 3), dtype=int)\n",
        "i = 0\n",
        "\n",
        "root = 'training_set/'\n",
        "for filename in os.listdir(root):\n",
        "    file = root + filename\n",
        "    with open(file) as f:\n",
        "        lines = f.readlines()\n",
        "        movie_idx = int(lines[0].split(':')[0])\n",
        "        for line in lines[1:]:\n",
        "            user_idx, score, _ = line.split(',')\n",
        "            user_idx, score = int(user_idx), int(score)\n",
        "            transactions[i] = movie_idx, user_idx, score\n",
        "            i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1603IYmm0ZsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Shuffle data\n",
        "p = np.random.permutation(len(transactions))\n",
        "transactions = transactions[p]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX2yPXQQ0kWE",
        "colab_type": "code",
        "outputId": "5aed1218-d37d-4f67-8fbe-69bac4f1f073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "transactions[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  11314, 2245510,       5],\n",
              "       [   9487, 1140115,       3],\n",
              "       [   7364, 1315428,       3],\n",
              "       [  10277, 1854102,       2],\n",
              "       [  15124,  467569,       5],\n",
              "       [  13582, 1486389,       5],\n",
              "       [  16100, 2463244,       5],\n",
              "       [  10607,  632738,       4],\n",
              "       [  14109, 1427281,       4],\n",
              "       [   1962, 2575787,       3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFlqjNI9FpAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PREPROCESS\n",
        "user_idxs = {x:i for i,x in enumerate(set(transactions[:, 1]))}\n",
        "\n",
        "X = np.zeros((transactions.shape[0], 2))\n",
        "\n",
        "#Movie id, translated to [0, n_movies-1]\n",
        "X[:, 0] = transactions[:, 0] - 1\n",
        "#User id, translated to [0, n_users-1], then offset by n_movies=17770\n",
        "X[:, 1] = 17770 + np.vectorize(user_idxs.get)(transactions[:, 1])\n",
        "\n",
        "X = X.astype(int)       #Cast to int to be able to index with them\n",
        "\n",
        "y = transactions[:, 2]  #Uncentered rating\n",
        "#y = (transactions[:, 2] - 3) / 2    #Rating, centered and scaled to [-1, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHLAPqbS5z4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rmse_score(y_true, y_pred):\n",
        "    return np.mean(np.square(y_true - y_pred))**0.5\n",
        "\n",
        "def r2_score(y, y_pred):\n",
        "    y_avg = y.mean()\n",
        "    ss_total = np.sum(np.square(y - y_avg))\n",
        "    ss_err = np.sum(np.square(y - y_pred))\n",
        "    return 1 - ss_err/ss_total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cIJqDsMSYCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KFolds:\n",
        "    def __init__(self, X, y, k=5):\n",
        "        self.k = k\n",
        "        self.X_folds = [X[i::k] for i in range(k)]\n",
        "        self.y_folds = [y[i::k] for i in range(k)]\n",
        "        \n",
        "    def get_fold(self, fold_i):\n",
        "        \n",
        "        X_cv = self.X_folds[fold_i]\n",
        "        y_cv = self.y_folds[fold_i]\n",
        "        \n",
        "        X_train = np.concatenate([self.X_folds[i] for i in range(self.k) if i != fold_i])\n",
        "        y_train = np.concatenate([self.y_folds[i] for i in range(self.k) if i != fold_i])\n",
        "        \n",
        "        return X_train, y_train, X_cv, y_cv\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9QfHIupoJ5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "class FactorizationMachineSparse:\n",
        "    def __init__(self, n, k):\n",
        "        self.w0 = 0\n",
        "        self.w = 0.01*np.random.randn(n)\n",
        "        self.v = 0.01*np.random.randn(n,k)\n",
        "\n",
        "        self.lr = 0.01\n",
        "        # Adam hyperparams\n",
        "        self.beta1 = 0.9\n",
        "        self.beta2 = 0.999\n",
        "        # Adam moments\n",
        "        self.v_dw0 = np.zeros_like(self.w0)\n",
        "        self.s_dw0 = np.zeros_like(self.w0)\n",
        "        self.v_dw = np.zeros_like(self.w)\n",
        "        self.s_dw = np.zeros_like(self.w)\n",
        "        self.v_dv = np.zeros_like(self.v)\n",
        "        self.s_dv = np.zeros_like(self.v)\n",
        "        # \n",
        "        self.t = 0\n",
        "        self.eps = 1e-8\n",
        "\n",
        "        #cache stuff to use in backward pass\n",
        "        self.x_batch = None\n",
        "        self.v_dot_x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x - [b x 2], where x_i = (movie_id, user_id)\n",
        "\n",
        "        #Cache\n",
        "        self.x_batch = x\n",
        "        self.v_dot_x = np.sum(self.v[x], axis=1)\n",
        "        \n",
        "        return self.w0   \\\n",
        "               + np.sum(self.w[x], axis=1)   \\\n",
        "               + 0.5 * np.sum(np.square(self.v_dot_x) - np.sum(np.square(self.v[x]), axis=1), axis=1)\n",
        "         \n",
        "    def backward(self, dLdy):\n",
        "        if self.x_batch is None:\n",
        "            assert 0, 'Call forward first'\n",
        "\n",
        "        #Gradient w.r.t. bias\n",
        "        dLdw0 = np.mean(dLdy)\n",
        "\n",
        "        #Gradient w.r.t. linear weights\n",
        "        dLdw = np.zeros(n)\n",
        "        for x, dLdyi in zip(self.x_batch, dLdy):\n",
        "            dLdw[x] +=  dLdyi\n",
        "        dLdw /= dLdy.shape[0]\n",
        "\n",
        "        #Gradient w.r.t. pairwise weights\n",
        "        dLdv = np.zeros((n,k))\n",
        "        for x, v_dot_xi, dLdyi in zip(self.x_batch, self.v_dot_x, dLdy):\n",
        "            dLdv[x] += dLdyi * (v_dot_xi - self.v[x])\n",
        "        dLdv /= dLdy.shape[0]\n",
        "\n",
        "        #ADAM: estimate moments\n",
        "        self.v_dw0 = self.beta1 * self.v_dw0 + (1 - self.beta1) * dLdw0\n",
        "        self.s_dw0 = self.beta2 * self.s_dw0 + (1 - self.beta2) * dLdw0 * dLdw0\n",
        "        self.v_dw = self.beta1 * self.v_dw + (1 - self.beta1) * dLdw\n",
        "        self.s_dw = self.beta2 * self.s_dw + (1 - self.beta2) * dLdw * dLdw\n",
        "        self.v_dv = self.beta1 * self.v_dv + (1 - self.beta1) * dLdv\n",
        "        self.s_dv = self.beta2 * self.s_dv + (1 - self.beta2) * dLdv * dLdv\n",
        "        #ADAM: correct moments\n",
        "        self.t+=1\n",
        "        bias_correction1 = 1 - self.beta1**self.t\n",
        "        bias_correction2 = 1 - self.beta2**self.t\n",
        "\n",
        "        step_size = self.lr / bias_correction1\n",
        "\n",
        "        denom_dw0 = np.sqrt(self.s_dw0) / math.sqrt(bias_correction2) + self.eps\n",
        "        denom_dw = np.sqrt(self.s_dw) / math.sqrt(bias_correction2) + self.eps\n",
        "        denom_dv = np.sqrt(self.s_dv) / math.sqrt(bias_correction2) + self.eps\n",
        "\n",
        "        #ADAM: Update weights\n",
        "        self.w0 -= step_size * self.v_dw0/denom_dw0\n",
        "        self.w -= step_size * self.v_dw/denom_dw\n",
        "        self.v -= step_size * self.v_dv/denom_dv\n",
        "        \n",
        "        #Clear cache\n",
        "        self.x_batch = None\n",
        "        self.v_dot_x = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTAY87PVZrPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MSE:\n",
        "    def __init__(self):\n",
        "        self.err = None\n",
        "    def forward(self, y_true, y_pred):\n",
        "        self.err = y_true - y_pred\n",
        "        return np.mean(np.square(self.err))\n",
        "    def backward(self):\n",
        "        if self.err is None:\n",
        "            assert 0, 'Call forward first'\n",
        "        return -2 * self.err\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMoe18AXYAdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch(X,y, i):\n",
        "  return X[i*batch_size:(i+1)*batch_size], \\\n",
        "         y[i*batch_size:(i+1)*batch_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gg8EOwyYQpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_movies = 17770\n",
        "n_users = len(user_idxs)\n",
        "\n",
        "n = n_movies + n_users\n",
        "k = 3\n",
        "\n",
        "criterion = MSE()\n",
        "kfold = KFolds(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oknK0gJZ9pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import trange\n",
        "\n",
        "rmses = []\n",
        "r2s = []\n",
        "\n",
        "epochs = 1\n",
        "for fold_i in range(kfold.k):\n",
        "    model = FactorizationMachineSparse(n,k)    \n",
        "    X_train, y_train, X_test, y_test = kfold.get_fold(fold_i)\n",
        "\n",
        "    #TRAIN\n",
        "    print(\" Train on fold {}\".format(fold_i+1))\n",
        "    \n",
        "    batch_size = 20000\n",
        "    iters = X_train.shape[0] // batch_size\n",
        "    if (X_train.shape[0] % batch_size > 0):\n",
        "        iters += 1\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch\", epoch+1)\n",
        "        running_loss = 0\n",
        "        running_r2 = 0\n",
        "        with trange(iters) as t:\n",
        "            for i in t:\n",
        "                X_batch, y_batch = get_batch(X_train,y_train, i)\n",
        "\n",
        "                y_pred = model.forward(X_batch)\n",
        "                loss = criterion.forward(y_batch, y_pred)\n",
        "                dLdy = criterion.backward()\n",
        "                model.backward(dLdy)\n",
        "\n",
        "                running_loss += loss\n",
        "                r2 = r2_score(y_batch, y_pred)\n",
        "                running_r2 += r2\n",
        "\n",
        "                t.set_postfix(mse=loss, r2=r2)\n",
        "        \n",
        "        running_loss /= X_train.shape[0]/batch_size\n",
        "        running_r2 /= X_train.shape[0]/batch_size\n",
        "        print()\n",
        "        print(\"MSE = {}, R2 = {}\".format(running_loss, running_r2))\n",
        "\n",
        "    #TEST\n",
        "    print(\" Test on {} fold\".format(fold_i+1))\n",
        "\n",
        "    batch_size = 20000\n",
        "    iters = X_test.shape[0] // batch_size\n",
        "    if (X_test.shape[0] % batch_size > 0):\n",
        "        iters += 1\n",
        "\n",
        "    y_pred = np.zeros(y_test.shape)\n",
        "    for i in trange(iters):\n",
        "        X_batch, _ = get_batch(X_test,y_test, i)\n",
        "        y_pred[i*batch_size:(i+1)*batch_size] = model.forward(X_batch)\n",
        "\n",
        "    print()\n",
        "    rmses.append(rmse_score(y_test, y_pred))\n",
        "    r2s.append(r2_score(y_test, y_pred))\n",
        "    print(\"RMSE = {}, R2 = {}\".format(rmses[-1], r2s[-1]))\n",
        "    print()\n",
        "\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tdanbQ211WO",
        "colab_type": "code",
        "outputId": "93f4aaaf-bfd0-40b2-b3a4-5088fc0e1cc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "print(\"Train:\")\n",
        "print(\"Folds\\t│{}  \\t{}\\t{}\\t{}\\t{}\\t│mean    std\".format(*range(1,kfold.k+1)))\n",
        "print(\"────────┼───────────────────────────────────────┼──────────────\")\n",
        "for name, metric in zip((\"RMSE\", \"R2\"), (train_rmses, train_r2s)):\n",
        "    print(\"{}\\t│{:.4f} {:.4f}  {:.4f}  {:.4f}  {:.4f}  │{:.4f}  {:.4f}\".format(name, *metric, np.mean(metric), np.std(metric)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:\n",
            "Folds\t│1  \t2\t3\t4\t5\t│mean    std\n",
            "────────┼───────────────────────────────────────┼──────────────\n",
            "RMSE\t│0.8826 0.8832  0.8832  0.8832  0.8967  │0.8858  0.0055\n",
            "R2\t│0.3410 0.3400  0.3400  0.3400  0.3090  │0.3340  0.0125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6crgtSEtVhq",
        "colab_type": "code",
        "outputId": "6ad77778-5cb5-4eda-9dde-36a1b09a346b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "print(\"Test:\")\n",
        "print(\"Folds\\t│{}\\t  {}\\t   {}\\t    {}\\t     {}\\t      │mean     std\".format(*range(1,kfold.k+1)))\n",
        "print(\"────────┼─────────────────────────────────────────────┼─────────────────\")\n",
        "for name, metric in zip((\"RMSE\", \"R2\"), (rmses, r2s)):\n",
        "    print(\"{}\\t│{:.6f} {:.6f} {:.6f} {:.6f} {:.6f} │{:.6f} {:.6f}\".format(name, *metric, np.mean(metric), np.std(metric)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test:\n",
            "Folds\t│1\t  2\t   3\t    4\t     5\t      │mean     std\n",
            "────────┼─────────────────────────────────────────────┼─────────────────\n",
            "RMSE\t│0.889122 0.888645 0.889551 0.889261 0.889428 │0.889201 0.000314\n",
            "R2\t│0.328927 0.329220 0.328134 0.328487 0.328351 │0.328624 0.000395\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}